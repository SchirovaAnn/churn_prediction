{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEEK 5. Эксперименты с моделью прогнозирования оттока."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решение.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. Подробные инструкции даны в приложенном jupyther notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, learning_curve, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"orange_small_churn_train_data.csv\")\n",
    "test_data = pd.read_csv(\"orange_small_churn_test_data.csv\")\n",
    "data = pd.concat((train_data.iloc[:,:-1], test_data), axis=0).drop(columns=['ID'])\n",
    "y = train_data.iloc[:,-1].fillna(-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удалим переменные, у которых пропущенно более 70% данных:\n",
    "NaN_num = (data.iloc[:, 0:190].isna().sum(axis = 0)/data.shape[0])\n",
    "NaN_cat = (data.iloc[:, 190:].isna().sum(axis = 0)/data.shape[0])\n",
    "\n",
    "NaN_num_del=[]\n",
    "for i in range(NaN_num.shape[0]):\n",
    "    if NaN_num[i]>=0.7: NaN_num_del.append(NaN_num.index[i])\n",
    "NaN_cat_del=[]\n",
    "for i in range(NaN_cat.shape[0]):\n",
    "    if NaN_cat[i]>0.7: NaN_cat_del.append(NaN_cat.index[i])\n",
    "        \n",
    "X_num = data.iloc[:, 0:190].drop(columns=NaN_num_del)\n",
    "X_cat = data.iloc[:, 190:].drop(columns=NaN_cat_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заполняем пропуски у числовых фич средним значением\n",
    "X_num = X_num.fillna(X_num.mean())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удалим признаки, у которых более 50 различных категорий\n",
    "unique = []\n",
    "for j in X_cat.columns:\n",
    "    if len(X_cat[j].dropna().unique())>50: unique.append(j)\n",
    "\n",
    "X_cat = X_cat.drop(columns=unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = pd.get_dummies(X_cat, dummy_na=True)    #примением Onehotencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объединим числовые и категориальные признаки\n",
    "common_data = pd.concat((X_num, X_cat), axis=1)\n",
    "\n",
    "X = common_data.iloc[:-10000,:]\n",
    "X_kaggle = common_data.iloc[-10000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBclf = GradientBoostingClassifier(random_state=1)\n",
    "cv_strategy = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7199740073732313"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка модели на кросс-валидации\n",
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores=learning_curve(GBclf, X, y, train_sizes=np.linspace(0.1, 1, 10), scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXxU1fn48c+TnbAExLBISAIuCMgeAaGCiLJIBbFS0dgqFpF+61a+VVF+9atfv7i3RXFBqtQtLoilgopY3ECksiggyL6HRbYkLIEQkuf3x70JQ3KTTEgmM0me9+s1r5k595w7z4xyn5xz7j1XVBVjjDGmqLBgB2CMMSY0WYIwxhjjyRKEMcYYT5YgjDHGeLIEYYwxxpMlCGOMMZ4sQRhTDiJyqYisC3YcxlQFsesgTHUhIluB0ao6L9ixGFMbWA/CGB8iEh7sGCqqJnwHExosQZhqT0TCRGS8iGwSkQMiMl1EzvLZ/r6I7BGRLBGZLyLtfba9JiIvicgnInIU6CciW0XkTyKy0m3znojEuPUvE5F0n/Yl1nW33yciu0Vkl4iMFhEVkfNK+B5nicg/3LoZIvIvt/wWEfmmSN3C/Xh8hwfc7xvuU3+4iKws6/cSkRgRecstzxSRJSLStCL/fUz1ZQnC1AR3AdcAfYFzgAzgBZ/tc4DzgSbA90BakfY3AhOB+kDBgfjXwCCgFdARuKWUz/esKyKDgHHAFcB5bnyleROIBdq7sf6tjPolfYdngKPA5UW2v+2+Lu33uhmIA1oCjYGxwLFyxGFqEEsQpia4HZigqumqmgM8DFwnIhEAqjpNVQ/7bOskInE+7T9U1YWqmq+qx92y51R1l6oeBGYDnUv5/JLq/hr4h6quVtVs4JGSdiAizYHBwFhVzVDVXFX9uhy/QdHv8A5wg7vv+sBVbhmU/nvl4iSG81Q1T1WXqeqhcsRhahBLEKYmSAJmukMimcAaIA9oKiLhIvKEO5xyCNjqtjnbp/0Oj33u8XmdDdQr5fNLqntOkX17fU6BlsBBVc0opU5piu77beBaEYkGrgW+V9Vt7rYSfy+cXsxc4F13qOspEYk8w5hMNWcJwtQEO4DBqtrQ5xGjqjtxhlaG4QzzxAHJbhvxaR+oU/l2Awk+71uWUncHcJaINPTYdhRn6AkAEWnmUee076CqPwHbcHolvsNLBZ/l+Xu5PZdHVLUd0Av4JfDbUuI2NZglCFPdRLoTqQWPCGAKMFFEkgBEJF5Ehrn16wM5wAGcg+xjVRjrdGCUiLQVkVjgoZIqqupunLmSF0WkkYhEikgfd/MKoL2IdHYnwB/28/Pfxplv6AO871Ne4u8lIv1EpIM7wX0IZ8gpz8/PMzWMJQhT3XyCM2la8HgYeBaYBXwmIoeB/wA93Ppv4PwlvRP4yd1WJVR1DvAc8CWwEVjkbsopoclvcA7Ia4G9wD3uftYD/wvMAzZwaiK9LO8AlwFfqOp+n/LSfq9mwAyc5LAG+Bp4y8/PMzWMXShnTBURkbbAKiBaVU8GOx5jymI9CGMCyL3+IEpEGgFPArMtOZjqwhKEMYF1O7AP2IQzlv/74IZjjP9siMkYY4yngPUgRGSaiOwVkVUlbBcReU5ENrrLFHT12TZIRNa528YHKkZjjDElC1gPwj1F7wjwhqpe5LH9KuBOnCs8ewDPqmoP9/S69cCVQDqwBLjBPa+7VGeffbYmJydX3pcwxpgabtmyZftVNd5rW0SgPlRV54tIcilVhuEkDwX+IyIN3eUGkoGNqroZQETedeuWmSCSk5NZunRpRUM3xphaQ0S2lbQtmJPULTh9eYB0t6ykck8iMkZElorI0n379gUkUGOMqY2CmSDEo0xLKfekqlNVNUVVU+LjPXtJxhhjzkDAhpj8kM7pa9MkALuAqBLKjTHGVKFgJohZwB3uHEMPIEtVd4vIPuB8EWmFszzCSJzFxowxNVhubi7p6ekcP3687Mqm3GJiYkhISCAy0v/FeQOWIESkYB2Ys907cP0PEAmgqlNw1tS5CmeNmmxglLvtpIjcgbPkcDgwTVVXBypOY0xoSE9Pp379+iQnJyPiNdJszpSqcuDAAdLT02nVqpXf7QJ5FtMNZWxX4A8lbPsEJ4EEXNqPaUz4fALbs7aTGJfIxP4TSe2QWhUfbYzxcfz4cUsOASIiNG7cmPKeyBPMIaagS/sxjTGzx5Cdmw3AtqxtjJk9BsCShDFBYMkhcM7kt63VazFN+HxCYXIokJ2bzYTPJwQpImOMCR21OkFsz9pernJjTM104MABOnfuTOfOnWnWrBktWrQofH/ixIlS2y5dupS77rqriiKtWrV6iCkxLpFtWcUvIkyMSwxCNMaY8qjM+cPGjRuzfPlyAB5++GHq1avHn/70p8LtJ0+eJCLC+3CZkpJCSkrKGX1uZcjLyyM8PDwg+67VPYiJ/ScSGxlbrHzw+YODEI0xxl8F84fbsrahaOH8YdqPaZX2Gbfccgvjxo2jX79+3H///SxevJhevXrRpUsXevXqxbp16wD46quv+OUvfwk4yeXWW2/lsssuo3Xr1jz33HPF9puXl8ctt9zCRRddRIcOHfjb3/4GwMaNG7niiivo1KkTXbt2ZdOmTagq9957b2Hd9957r/Az+/Xrx4033kiHDh3Iy8vj3nvv5eKLL6Zjx468/PLLlfIb1OoeRMFfGwV/hSQ0SKB+VH2mLJ1C27PbclePmtltNCbU3fPpPSzfs7zE7f9J/w85eaffuTU7N5vfffg7/r7s755tOjfrzKRBk8oVx/r165k3bx7h4eEcOnSI+fPnExERwbx583jwwQf54IMPirVZu3YtX375JYcPH6ZNmzb8/ve/P+3ag+XLl7Nz505WrXIWus7MzAQgNTWV8ePHM3z4cI4fP05+fj7//Oc/Wb58OStWrGD//v1cfPHF9Onj3Kp88eLFrFq1ilatWjF16lTi4uJYsmQJOTk59O7dmwEDBpTrlFYvtTpBgJMkfLulx08e58YPbuTuT+9mf/Z+HrnsETuzwpgQUzQ5lFV+pkaMGFE4fJOVlcXNN9/Mhg0bEBFyc3M92wwZMoTo6Giio6Np0qQJP//8MwkJCYXbW7duzebNm7nzzjsZMmQIAwYM4PDhw+zcuZPhw4cDzkVtAN988w033HAD4eHhNG3alL59+7JkyRIaNGhA9+7dCxPAZ599xsqVK5kxY0ZhrBs2bLAEUdliImKYPmI6Yz8ay6PzH+VA9gEmXzWZMKnVo3HGVKmy/tJPnpTsOX+YFJfEV7d8VWlx1K1bt/D1n//8Z/r168fMmTPZunUrl112mWeb6Ojowtfh4eGcPHn6HWYbNWrEihUrmDt3Li+88ALTp09n0iTv71va7Rh8Y1NVJk+ezMCBA/35Wn6zo56HiLAI/n7137mv1328uPRFUv+Zyom80s9kMMZUHa/5w9jIWCb2nxiwz8zKyqJFC2dh6ddee+2M97N//37y8/P51a9+xaOPPsr3339PgwYNSEhI4F//+hcAOTk5ZGdn06dPH9577z3y8vLYt28f8+fPp3v37sX2OXDgQF566aXCXs369es5evToGcdYwHoQJRARnrzySRrHNub+efeTeTyTGSNmUDeqbtmNjTEBVXT+sCpWQbjvvvu4+eab+etf/8rll19+xvvZuXMno0aNIj8/H4DHH38cgDfffJPbb7+dhx56iMjISN5//32GDx/OokWL6NSpEyLCU089RbNmzVi7du1p+xw9ejRbt26la9euqCrx8fGFyaYiatQ9qVNSUjQQNwx69ftXGfPRGHom9OSjGz6iUZ1Glf4ZxtR2a9asoW3btsEOo0bz+o1FZJmqep6na0NMfvhd19/x/oj3WbprKX1e68Puw7uDHZIxxgScJQg/Xdv2Wj658RO2Zm6l97TebDq4KdghGWNMQFmCKIf+rfvzxW+/4FDOIXpP682KPSuCHZIxxgSMJYhyurjFxSwYtYDI8Ej6vtaXb7Z/E+yQjDEmICxBnIG28W1ZeOtCmtVrxoA3B/DJhiq5dYUxxlQpSxBnKDEukQWjFtAuvh3D3h1G2srKWwPGGGNCgV0HUQHxdeP54uYvuObda7hp5k1kHM/gju53BDssY0w5HThwgP79+wOwZ88ewsPDiY+PB5w1j6Kiokpt/9VXXxEVFUWvXr0CHmtVsh5EBTWIbsAnqZ9wzYXXcOecO3nkq0dKvTzeGFNJ0tIgORnCwpzntDPvxRcs9718+XLGjh3LH//4x8L3ZSUHcBLEt99+e8afXx5Fl+4IJEsQlSAmIob3R7zPqM6jePjrh7lrzl3ka36wwzKm5kpLgzFjYNs2UHWex4ypUJIoatmyZfTt25du3boxcOBAdu92rn967rnnaNeuHR07dmTkyJFs3bqVKVOm8Le//Y3OnTuzYMGC0/bz9ddfF958qEuXLhw+fBiAp556ig4dOtCpUyfGjx8POCu99uzZk44dOzJ8+HAyMjIAuOyyy3jwwQfp27cvzz77bImxVTYbYqokEWERvDr0VRrXacwzi57hwLEDvH7N60SGR5bd2BhzunvugeUlL/fNf/4DOUVWbs3Oht/9Dv7uvdw3nTtDCYviFaWq3HnnnXz44YfEx8fz3nvvMWHCBKZNm8YTTzzBli1biI6OJjMzk4YNGzJ27NhiNxkq8Mwzz/DCCy/Qu3dvjhw5QkxMDHPmzOFf//oX3333HbGxsRw8eBCA3/72t0yePJm+ffvy0EMP8cgjjxQu5JeZmcnXX39Nbm4uffv29YytslmCqEQiwtMDnubs2LMZ//l4Z/2mX8/wvCmRMaYCiiaHssrLvfscVq1axZVXXgk4N/lp3rw5AB07diQ1NZVrrrmGa665psx99e7dm3HjxpGamsq1115LQkIC8+bNY9SoUcTGOseGs846i6ysLDIzM+nbty8AN998MyNGjCjcz/XXXw/AunXrSoytsgU0QYjIIOBZIBx4RVWfKLK9ETANOBc4DtyqqqvcbVuBw0AecLKktUJC0f2/uJ+z6pzF2I/HMuDNAXx040c0jGkY7LCMqT7K+ks/OdkZVioqKQm++qrCH6+qtG/fnkWLFhXb9vHHHzN//nxmzZrFo48+yurVq0vd1/jx4xkyZAiffPIJPXv2ZN68eahque8zU7C8d2mxVbaAzUGISDjwAjAYaAfcICLtilR7EFiuqh2B3+IkE1/9VLVzdUoOBW7rdhvvXfceS3Ytoe9rfW39JmMq08SJEFukZx4b65RXgujoaPbt21d4EM7NzWX16tXk5+ezY8cO+vXrx1NPPUVmZiZHjhyhfv36hXMLRW3atIkOHTpw//33k5KSwtq1axkwYADTpk0jOzsbgIMHDxIXF0ejRo0K5zDefPPNwt6ErzZt2njGFgiBnKTuDmxU1c2qegJ4FxhWpE474HMAVV0LJItI0wDGVKWua3cdH9/4MZsObuIX//gFmzM2BzskY2qG1FSYOtXpMYg4z1OnOuWVICwsjBkzZnD//ffTqVMnOnfuzLfffkteXh433XQTHTp0oEuXLvzxj3+kYcOGXH311cycOdNzknrSpElcdNFFdOrUiTp16jB48GAGDRrE0KFDSUlJoXPnzjzzzDMAvP7669x777107NiR5cuX89BDDxWLLSoqyjO2QAjYct8ich0wSFVHu+9/A/RQ1Tt86jwGxKjqOBHpDnzr1lkmIluADECBl1V1agmfMwYYA5CYmNhtm1e3M8gW71zM4LTBRIVH8dlNn9GhaYdgh2RMyLHlvgMvlJb79hpgK5qNngAaichy4E7gB6DgJN/eqtoVZ4jqDyLSx+tDVHWqqqaoakrBhS2hpnuL7iwYtYBwCafPa334dkfVnC9tjDEVEcgEkQ609HmfAOzyraCqh1R1lKp2xpmDiAe2uNt2uc97gZk4Q1bVVrv4diy8dSFN6jbhijeuYM6GOcEOyRhjShXIBLEEOF9EWolIFDASmOVbQUQautsARgPzVfWQiNQVkfpunbrAAGBVAGOtEkkNk1gwagFt49sy9N2hvPPjO8EOyZiQYqsQBM6Z/LYBSxCqehK4A5gLrAGmq+pqERkrImPdam2B1SKyFmco6W63vCnwjYisABYDH6vqp4GKtSo1qduEL2/+kt4te5P6z1ReXPJisEMyJiTExMRw4MABSxIBoKocOHCAmJiYcrWze1IHyfGTx7l+xvXMWjeLRy57hHMbncuEL6ruBuzGhJrc3FzS09M5fvx4sEOpkWJiYkhISCAy8vTVHUqbpLYEEUQn808yetZoXl/xOhFhEZzMP7UIV2xkLFOvnmpJwhgTUME6i8mUISIsgmnDplE/qv5pyQEgOzebCZ9PCFJkxhhjCSLowiSMIyeOeG7bnrW9iqMxxphTLEGEgMS4RM/yuOg4DuUcquJojDHGYQkiBEzsP7HYiq9hEkZmTiZJk5J46MuHOJB9IEjRGWNqK0sQISC1QypTr55KUlwSgpAUl8Qbw99g2ZhlXN7qch6d/yhJk5K479/3sefInmCHa4ypJewspmpg9d7VPP7N47yz6h2iwqMY3WU09/W+j5ZxLctubIwxpbCzmKq59k3a89a1b7HujnWkdkhlyrIpnPvcudw26zY2HdwU7PCMMTWUJYhq5LyzzuOVoa+w6a5N3N7tdt5c+SYXPH8Bv5n5G37a91OwwzPG1DCWIKqhxLhEJl81mS13b2Fcz3HMXDOTi168iOumX8cPu38IdnjGmBrCEkQ11rx+c54e8DRb79nKhEsnMG/zPLpO7cqQt4ewaEfgb0dojKnZLEHUAGfHns2jlz/Ktnu2MfHyiXyX/h29pvWi/xv9+XLLl7b4mTHmjFiCqEHiYuJ48NIH2XbPNv4y4C+s2beGy9+4nN7TevPJhk8sURhjysUSRA1UN6ou4y4Zx+a7N/PiVS+y8/BOhrw9hG5Tu/HPNf8kX/ODHaIxphqwBFGDxUTE8PuLf8/GOzcybeg0jpw4wq+m/4oOL3UgbWVasQUCjTHGlyWIWiAyPJJRXUax5g9reOdX7xAmYdw08yYufP5CXv3+VU7knQh2iMaYEGQJohYJDwtn5EUjWTF2BTOvn0nDmIaMnj2a8547j+cXP88/fvgHyZOSCXskjORJyaT9mBbskI0xQWRLbdRiqspnmz7j0fmPsnDHwmLb7aZFxtR8ttSG8SQiDDxvIAtGLaBp3abFtmfnZjN+3vggRGaMCQWWIAwiwt6jez23pR9K5+K/X8xDXz7Eoh2LyMvPq+LojDHBYgnCAKXftCgqPIqJCybSa1ovmjzThBs+uIE3VrxRYlIxxtQMEcEOwISGif0nMmb2GLJzswvLYiNjeWHIC6R2SOXgsYP8e9O/mbNxDp9u/JR3V70LQLfm3Rh83mAGnz+YHi16EB4WHqyvYIypZAGdpBaRQcCzQDjwiqo+UWR7I2AacC5wHLhVVVf509aLTVJXTNqPaUz4fALbs7aTGJfIxP4TPSeo8zWf5XuWM2fDHOZsnMOi9EXkaz6NYhox4NwBDD5vMIPOG0TTesXnNYwxoaW0SeqAJQgRCQfWA1cC6cAS4AZV/cmnztPAEVV9REQuBF5Q1f7+tPViCSI4Mo5l8O/Np3oXBXe969q8q9O7OG8wPRJ6EBFmHVZjQk2wEsQlwMOqOtB9/wCAqj7uU+dj4HFV/cZ9vwnoBbQuq60XSxDBl6/5rNizgjkb3d7FjkXkaR6NYhpx5blXFvYumtVrFuxQjTGUniAC+SddC2CHz/t0oEeROiuAa4FvRKQ7kAQk+NnWhKAwCaNL8y50ad6FBy99kIxjGczbPK+wdzF99XQAujTrUjh30TOh52m9C3+HuowxgRXIBCEeZUW7K08Az4rIcuBH4AfgpJ9tnQ8RGQOMAUhM9D4TxwRPozqNGNF+BCPaj0BVWfHzisK5iycXPslj3zxGw5iGXNna6V1k52Zz37z7CifLt2VtY8zsMQCWJIypYkEdYipSX4AtQEegfXnaFrAhpuol83im07twE8buI7tLrJsUl8TWe7ZWXXDG1BLBGmJaApwvIq2AncBI4MYigTUEslX1BDAamK+qh0SkzLam+msY05Dr2l3Hde2uQ1VZ+fNKOr/c2bPu9qztVRydMSZgF8qp6kngDmAusAaYrqqrRWSsiIx1q7UFVovIWmAwcHdpbQMVqwk+EaFTs04kxSWVuP3PX/yZXYd3VXFkxtRetlifCSlpP6YVu2AvOjyadvHtWL5nOeFh4YxoN4K7e9xNjwQ7b8GYirLF+ky1kdohlalXTyUpLglBSIpL4tVhr/L97d+z/s713HHxHXy84WN6vtqTnq/05O0f37b7WRgTINaDMNXO4ZzDvL7idZ777jk2HNxA83rN+X3K77k95Xaa1G0S7PCMqVaCcqFcMFiCqF3yNZ9PN37Ks989y2ebPiM6PJobOtzA3T3upnMz78luY8zpLEGYGm/NvjVMXjyZ11e8TnZuNpcmXsrdPe5m2IXDbIkPY0phCcLUGhnHMpj2wzSeX/I8WzO3khiXyB8u/gOju47mrDpnBTs8Y0KOJQhT6+Tl5zF7/Wye/e5Zvtr6FXUi6vCbjr/hrh530b5J+2CHZ0zIsARharUVe1YwefFk3lr5Fjl5OVzR+gru6n4XQy4YQpjYiXymdrMEYQywP3s/f1/2d15Y8gI7D+/k3Ebncmf3OxnVZRQNohsEOzxjgsKugzAGODv2bB649AG23L2Fd3/1Lk3rNeWeuffQ4q8tuGvOXWw4sCHYIRoTUixBmFonMjyS6y+6noW3LmTx6MVcc+E1TFk6hQuev4Ahbw/hs02foaqk/ZhG8qRkwh4JI3lSMmk/pgU7dGOqlA0xGQPsPrybl5e9zEtLX2Lv0b2cU+8c9mfv50T+qau0YyNjmXr1VFt23NQoNgdhjJ9yTuYwffV0Rs8afVpyKGDLjpuaxuYgjPFTdEQ0v+n0G3Lzcz23b8vaxm2zbuOtlW/ZEuSmxrNLTI3xkBiXyLasbcXK60TUYcaaGbzywyuA06Pom9yXPol96JPUh/POOg/n3lfGVH+WIIzxMLH/xGLLjhfMQYxsP5JVe1cxf9t8vt72NXM2zOGNFW8A0Lxec/okOcmib1Jf2sa3tWstTLVlcxDGlCDtxzQmfD6B7VnbSYxLZGL/iZ4T1KrKugPr+Hrr18zfPp+vt37NzsM7AWhcpzGXJl1K36S+9EnqQ6emnQgPC6/qr2JMiWyS2pgqpKpsydzC/G3zC3sZmzM2A9AgugG/SPwFfRL70De5L92adyMyPDLIEZvazBKEMUGWfii9MGHM3zafNfvXAM6w1SUJlxT2MLq36E6dyDqntfW3J2PMmbAEYUyI2Xt0Lwu2LXASxvb5rNizAkWJCo+ie4vuhQkj/VA6d86503MuxJKEqQyWIIwJcRnHMli4Y2HhPMayXcvI07wS6zet25S5N82lfnR9GkQ3oEF0A6LCowIao/VkaiZLEMZUM0dOHOHbHd8y8K2BfreJCo+iQXQD6kedShoFCeS0Mve1b3LxLasfVb/YvEjaj2klntVlSaJ6swRhTDWVPCnZ83qMJnWbMGXIFA7lHOLwicMcyjnkvM45zKET7nNBmc923wN8aepE1Dktufy07ydy8nKK1bMry6u/0hKEXQdhTAgr6XqMvw78K8PbDi/3/k7mn+TIiSOeCcSzzH3+Yc8PnvvblrWN73d/T5dmXewCwRqozAQhIo8BT6lqpvu+EfDfqvr//Gg7CHgWCAdeUdUnimyPA94CEt1YnlHVf7jbtgKHgTzgZEkZzpiarGD4prLG/iPCImgY05CGMQ3L1a6kngxAt6ndSGiQwNALhjK0zVAuS76M6IjoM4rPhJYyh5hE5AdV7VKk7HtV7VpGu3BgPXAlkA4sAW5Q1Z986jwIxKnq/SISD6wDmqnqCTdBpKjqfn+/jA0xGRMYJc1B/OXKvxATGcOsdbOYu2ku2bnZ1I+qz6DzBjGszTAGnz/Y7gUe4io6xBQuItGqmuPurA7gz58H3YGNqrrZbfcuMAz4yaeOAvXF6ZvWAw4CJ/3YtzGmCpXVk7ml8y0cyz3GF1u+4MN1HzJ7/Wze/+l9wiWcS5MuZVibYQxtM5TWjVoH82uYcvKnB3EfMBT4B84B/VZglqo+VUa764BBqjraff8boIeq3uFTpz4wC7gQqA9cr6ofu9u2ABnuZ76sqlNL+JwxwBiAxMTEbtu2eXeDjTFVJ1/zWbJzCbPWzWLW+lms2rsKgIuaXFQ4FHVxi4ttnaoQUOGzmERkMNAfEOAzVZ3rR5sRwMAiCaK7qt7pU+c6oDcwDjgX+DfQSVUPicg5qrpLRJq45Xeq6vzSPtOGmIwJTZsObmL2+tnMWjeL+dvmk6d5NKvXjKsvuJphbYZxeavLi11BbqpGUE5zFZFLgIdVdaD7/gEAVX3cp87HwBOqusB9/wUwXlUXF9nXw8ARVX2mtM+0BGFM6Dt47CBzNszhw3Uf8unGTzl84jCxkbEMOHcAw9oMY8j5Q4ivGx/sMGuNCiUIETmMM8wDEAVEAkdVtUEZ7SJwJqn7AztxJqlvVNXVPnVeAn5W1YdFpCnwPdAJOAaEqephEamL04P4X1X9tLTPtARhTPWSczKHr7Z+VTgUlX4onTAJo1fLXoVDUW3ObnNaG7uiu3JVag9CRK7BGSp60I+6VwGTcE5znaaqE0VkLICqThGRc4DXgOY4w1dPqOpbItIamOnuJgJ4W1UnlvV5liCMqb5UlR/2/MCsdbP4cN2HLN+zHIA2jdswtM1QhrUZxuaMzYz9eKxd0V2JKn2ISUT+o6o9KxxZJbMEYUzNsT1rO7PXzebDdR/y1davyM3PJUzCyNf8YnXtiu4zV9Ehpmt93oYBKUBfVb2k8kKsHJYgjKmZso5n8enGTxn5wcgS66z9w1ouaHyBXdFdThVNEP/weXsS2Ar8XVX3VlqElcQShDE1W2lXdINzB79eLXvRu2Vveif2JuWcFGIiYqowwuqnQhfKqeqoyg/JGGPKr6S1qR7u+zCN6jTi2x3fsnDHQmavnw1AZFgk3c7pRu+WvQsTR9N6TYMVfrXjTw8iBvgd0B4oTMWqemtgQys/60EYU/P5cxbTvnZylmwAABUKSURBVKP7WJS+iIXbF7Jwx0KW7lpauBpt60atnR6GmzTaN2lfqy/Yq+gQ0/vAWuBG4H+BVGCNqt5d2YFWlCUIY4yXnJM5fL/7+8IexsIdC9l71Bklj4uO45KWl9AroRe9E3vTvUV36kXVC3LEVaeiCeIHVe0iIitVtaOIRAJzVfXyQARbEZYgjDH+UFU2Z2x2ksX2hXyb/i2r965GUcIlnE7NOp02LNUyruVp7WvStRgVTRCLVbW7iMwH/gvYAyxW1ZBbdcsShDHmTGUez2TRjkWFvYzvdn5XONfRskHLwmRxKOcQj33zWI25FqOiCWI08AHQAeeitnrAn1X15UqOs8IsQRhjKktuXi4rf15ZOCS1cPtCdh7eWWL9+Nh4po+YTqOYRjSq04hGMY2oF1UvoKfdVkZPJqBrMYnIzar6eoV2UkksQRhjAml71naSJiX5XT8iLOK0hFHwfFads4qVFy2LjYwtNblU1n3CA50gyrx5UFWxBGGMCbSSrsVoXq85ademcfDYQTKOZ5BxLOO056LlmcczPa8KLxAZFumZOAoSzOTFk8k4nlGsXXmvKg/0PantskVjTK1R0rUYTw94mn6t+vm9n3zN51DOoWKJJONY8WSScTyDPUf2sGbfGjKOZ5B1PAvF+4/77VnbK/wdC1RGggjMeuHGGBOCKus+4WESVnh/8Fa0KlfbvPw8kp9NJv1QerFtiXGJ5dpXaawHYYwx5ZTaITWoZyyFh4XzxBVPePZkJvYvc+Frv1XG5YMLK2EfxhhjyiG1QypTr55KUlwSgpAUl1Tpp9r6c5rrY8BTqprpvm8E/Leq/r9Ki6KS2CS1McaUT2mT1P70IAYXJAcAVc0Arqqs4IwxxoQmfxJEuIhEF7wRkTpAdCn1jTHG1AD+TFK/BXzu3hdCgVuBkLgwzhhjTOD4cz+Ip0RkJXCFW/Soqs4NbFjGGGOCzd/TXH8AInF6ED8ELhxjjDGhosw5CBH5NbAYuA74NfCdiFwX6MCMMcYElz89iAnAxQX3oBaReGAeMCOQgRljjAkuf85iCitIDq4DfrZDRAaJyDoR2Sgi4z22x4nIbBFZISKrRWSUv22NMcYEVqk9CHHWml0iInOBd9zi64FPytqxiIQDLwBXAunufmap6k8+1f4A/KSqV7s9k3Uikgbk+dHWGGNMAJXaE1DnMuvOwMtAR6ATMFVV7/dj392Bjaq6WVVPAO8Cw4p+BFDfTUT1gIPAST/bGmOMCSB/5iAWATtUdVw5990C2OHzPh3oUaTO88AsYBdQH7heVfNFxJ+2AIjIGGAMQGJi5a1iaIwxtZ0/cwn9gEUisklEVhY8/Gjntcpr0YWfBgLLgXNweirPi0gDP9s6hapTVTVFVVPi4+P9CMsYY4w//OlBDD7DfacDLX3eJ+D0FHyNAp5wh7I2isgW4EI/2xpjjAkgf66kLn5vPf8sAc4XkVbATmAkcGOROtuB/sACEWkKtAE2A5l+tDXGGBNAlXHDIE+qelJE7gDmAuHANFVdLSJj3e1TgEeB10TkR5xhpftVdT+AV9tAxWqMMaa4Mu8HUZ3Y/SCMMaZ8Kno/CGOMMbWQJQhjjDGeLEEYY4zxZAnCGGOMJ0sQxhhjPFmCMMYY48kShDHGGE+WIIwxxniyBGGMMcaTJQhjjDGeLEEYY4zxZAnCGGOMJ0sQxhhjPFmCMMYY48kShDHGGE+WIIwxxniyBGGMMcaTJQhjjDGeLEEYY4zxZAnCGGOMJ0sQxhhjPFmCMMYY4ymgCUJEBonIOhHZKCLjPbbfKyLL3ccqEckTkbPcbVtF5Ed329JAxmmMMaa4iEDtWETCgReAK4F0YImIzFLVnwrqqOrTwNNu/auBP6rqQZ/d9FPV/YGK0RhjTMkC2YPoDmxU1c2qegJ4FxhWSv0bgHcCGI8xxphyCGSCaAHs8Hmf7pYVIyKxwCDgA59iBT4TkWUiMqakDxGRMSKyVESW7tu3rxLCNsYYA4FNEOJRpiXUvRpYWGR4qbeqdgUGA38QkT5eDVV1qqqmqGpKfHx8xSI2xhhTKJAJIh1o6fM+AdhVQt2RFBleUtVd7vNeYCbOkJUxxpgqEsgEsQQ4X0RaiUgUThKYVbSSiMQBfYEPfcrqikj9gtfAAGBVAGM1xhhTRMDOYlLVkyJyBzAXCAemqepqERnrbp/iVh0OfKaqR32aNwVmikhBjG+r6qeBitUYY0xxolrStED1k5KSokuX2iUTxhjjLxFZpqopXtvsSmpjjDGeLEEYY4zxZAnCGGOMJ0sQxpjqJS0NkpMhLMx5TksLdkTBE+DfwhKEMab6SEuDMWNg2zZQdZ7HjKn6JBEKSaoKfgs7i8kYE7oOH4YdO049/vQnyMoqXq9ePbjtNqhT5/RHbGzxspIekZEgXgtAFFFwYM7OPlUWGwtTp0Jqqneb/Hyn/tGjcOTI6Q9/y4qWHzjg/VlJSbB1a9nfw1XaWUyWIIwxwZGTA+nppyeA7dtPf5+Z6f/+6tWDY8cgL+/M4gkL8y+hzJnjHKiLqlMHLr3U+wDvVb+s71KvHtSte+p10fcvvujdVsRJSH4qLUEE7EI5Y6q9tDSYMME5aCUmwsSJJf+FWBuU5/fIy4M9e4of8H3f//xz8XZnnw0tW0KrVtCnj/M6MdF5btnSKdu+vXg737+ac3OdRFHwyM4+/X1Zj5LqZ2Y6zyUd7I8dc3o39epBfHzJB/myyurUcZJVWT7+2BlWKioxsey2frIEYYyXosMIBeO7UPVJIhQSldfvMXo0LFsGrVsXP/jv2gUnT56+j3r1Th3sO3cufvBPSHD+gi/NY495D+9MnHjqfWSk82jQoHK+e1HJyd4H5qQk+M9/AvOZXiZOLPu3qCAbYjLGS8uWzvBHUXFx8MADzj9Efx8xMf6NbXs5k/HuolTh+PGShz5Keu/7+uuvnSGhkkRFOQd43wN+0QQQF3fmv4OvYCfMyvhvUpmxVPC3sDkIY0pz4gSsWOH89bdokfO8ZUvlfkZ5Eorv47HH4ODB4vuLi4OxY/0/6JdjTJqYmOLDHt99511XBHbvdoZU/BkWqSmCnaQqkSUIY3zt3OkkgYKEsGyZ8xc2QIsWcMklMG+e9wRpYiKsXev89Ximj6NHy66Tm1v294iKKn0S80zfh4cX/6zShlXKccaMCT02SW1qr5wc+P7703sHO9wbHUZFQbdu8F//BT17OokhIcHZVtIwwmOPnTqbpXHjwMVdMNHavr33UFdiovcBO1CqYLzbhB5LEKbmUHUO/gWJYNEi+OEHZwgJnL92e/VyEkHPns5EaXS0974KhguCNYxQMNH6xBMlJ6qqFOzfwwSFDTGZ6uvYMVi69PTewe7dzrY6dSAl5VTPoGdPaN48uPGeqRo03m1Cjw0xmerF64B4443OxLFv72DFilOnUrZuDZdffiohdOzo/AVeE6SmWkIwQWE9CBNavMb+w8OdYZXDh533detC9+5OMih4NGkSnHiNqeasB2FCV1YW/PQTrF7tPKZMOXVGUYG8POc0zZdecnoH7dtDhP2va0yg2b8yUzUOHz49ERQ8fM/QqVOneHIokJ3tnPdvjKkyliBM5Tp6FNasOZUAVq1ynn3Xz4mOhrZtoW9fpzdQ8EhOhnPPDfj6MsYY/1iCMKeU52yZY8dOTwQFj61bndNNwbnO4MILoXdvZ16hIBG0bu19MRbY+fbGhBBLEMZR0uJ0ubnQpcvpvYHVq2Hz5lOJIDISLrgALr4YbrnFSQIXXeT0Bso7V2Dn2xsTMgJ6FpOIDAKeBcKBV1T1iSLb7wUK/uVHAG2BeFU9WFZbL3YW0xnIy4O9e6FrV2d55tKEhzuJwHdYqH17OP/8mnNKqTG1TFDOYhKRcOAF4EogHVgiIrNU9aeCOqr6NPC0W/9q4I9uciizrSlDXh7s2+csu7x7t/Nc9PWuXc6a/GUt5Pbuu04iuOACZ9jIGFMrBHKIqTuwUVU3A4jIu8AwoKSD/A3AO2fYtvrzd/w/P9//A7/XnbXi4+Gcc5xHp06nXv/P/zj7LSopCa6/vvK/rzEm5AUyQbQAdvi8Twd6eFUUkVhgEHDHGbQdA4wBSKyuZ7p4jf/feivMnOlcAOabBPbsKX4jFnDuxFVwsO/Q4dTr5s1PvW7atOQeQIMGNjlsjDlNIBOE151BSprwuBpYqKoFC9/73VZVpwJTwZmDKG+QIeG++04/MIOzwNwHHzgrhhYc4Nu3P/Xa9+DfrFnFh35sctgYU0QgE0Q60NLnfQKwq4S6Izk1vFTettXXjh3wf//n9A68iMD+/VUXj635Y4zxEchbQC0BzheRViIShZMEZhWtJCJxQF/gw/K2rbZ27YI77oDzzoPXXnNu1OKlug6ZGWNqhIAlCFU9iTOnMBdYA0xX1dUiMlZEfNdMGA58pqpHy2obqFirzM8/w7hxzvUBL7/sXDOwYYOz/lDRm7Xb+L8xJshsNdeqsH8/PP00PP+8c4ez3/4W/vxnaNXqVB1b898YEwS2mmuwZGTAX/4Czz7rrFGUmgoPPeRcWFaUjf8bY0KMJYhAyMqCSZPgr3+FQ4fg17+Ghx92FqgzxphqwhJEZTpyBCZPdoaTMjJg+HB45BHnugRjjKlmLEFUhuxsePFFePJJZ77hl790EkPXrsGOzBhjzlggT3Ot+Y4fd+YXWreGe++Fbt2c+yXPnm3JwRhT7VkP4kzk5MCrrzpnGu3aBf36wYwZ8ItfBDsyY4ypNJYgyiM3F15/HR591DkdtXdveOstJ0EYY0wNY0NM/jh50kkMF14It93mrIE0dy4sWGDJwRhTY1mCKE1eHrz9trNI3i23QMOG8NFHsGgRDBjgrJVkjDE1lCUIL/n5zpxCx47OxWvR0c7S20uXwpAhlhiMMbWCJYi0NEhOhrAw5+Y448Y5ZyCNGOHcc3n6dFi+HK65xhKDMaZWqd2T1EVv1LN9O/ztb86Ndd56C0aOdO7DbIwxtVDtThATJhS/UQ84Q0q2LpIxppar3UNM27d7l+/Y4V1ujDG1SO1OECXdkMdu1GOMMbU8QUycaDfqMcaYEtTuBJGaClOnOmcviTjPU6fa/IMxxlDbJ6nBbtRjjDElqN09CGOMMSWyBGGMMcaTJQhjjDGeLEEYY4zxZAnCGGOMJ1HVYMdQaURkH7Ctij7ubGB/FX1WZaqucUP1jd3irloWd/kkqWq814YalSCqkogsVdWUYMdRXtU1bqi+sVvcVcvirjw2xGSMMcaTJQhjjDGeLEGcuanBDuAMVde4ofrGbnFXLYu7ktgchDHGGE/WgzDGGOPJEoQxxhhPliBcItJSRL4UkTUislpE7nbLzxKRf4vIBve5kU+bB0Rko4isE5GBPuXdRORHd9tzIiJVEH+4iPwgIh9Vs7gbisgMEVnr/vaXVIfYReSP7v8nq0TkHRGJCcW4RWSaiOwVkVU+ZZUWp4hEi8h7bvl3IpIcwLifdv8/WSkiM0WkYajFXVLsPtv+JCIqImeHYuzFqKo9nHmY5kBX93V9YD3QDngKGO+WjweedF+3A1YA0UArYBMQ7m5bDFwCCDAHGFwF8Y8D3gY+ct9Xl7hfB0a7r6OAhqEeO9AC2ALUcd9PB24JxbiBPkBXYJVPWaXFCfwXMMV9PRJ4L4BxDwAi3NdPhmLcJcXulrcE5uJczHt2KMZe7LsEasfV/QF8CFwJrAOau2XNgXXu6weAB3zqz3X/YzYH1vqU3wC8HOBYE4DPgcs5lSCqQ9wNcA60UqQ8pGPHSRA7gLNw7qnykXvwCsm4gWROP9BWWpwFddzXEThXAksg4i6ybTiQFopxlxQ7MAPoBGzlVIIIudh9HzbE5MHtsnUBvgOaqupuAPe5iVut4CBRIN0ta+G+LloeSJOA+4B8n7LqEHdrYB/wD3d47BURqRvqsavqTuAZYDuwG8hS1c9CPW4flRlnYRtVPQlkAY0DFvkpt+L8VX1aDEXiC5m4RWQosFNVVxTZFNKxW4IoQkTqAR8A96jqodKqepRpKeUBISK/BPaq6jJ/m3iUVXncrgicrvhLqtoFOIoz5FGSkIjdHbMfhjMkcA5QV0RuKq2JR1mwfvPSnEmcVf4dRGQCcBJIKyOGkIhbRGKBCcBDXptLiCMkYrcE4UNEInGSQ5qq/tMt/llEmrvbmwN73fJ0nDHFAgnALrc8waM8UHoDQ0VkK/AucLmIvFUN4i6IJV1Vv3Pfz8BJGKEe+xXAFlXdp6q5wD+BXtUg7gKVGWdhGxGJAOKAg4EKXERuBn4JpKo7xlIN4j4X54+JFe6/0wTgexFpFuqxW4JwuWcIvAqsUdW/+myaBdzsvr4ZZ26ioHyke0ZBK+B8YLHbZT8sIj3dff7Wp02lU9UHVDVBVZNxJqy+UNWbQj1uN/Y9wA4RaeMW9Qd+qgaxbwd6ikis+3n9gTXVIO4ClRmn776uw/n/L1B/iQ8C7geGqmp2ke8TsnGr6o+q2kRVk91/p+k4J8TsCfXYAzKJVx0fwC9wumkrgeXu4yqcsb3PgQ3u81k+bSbgnHWwDp+zT4AUYJW77XkCNIHk8R0u49QkdbWIG+gMLHV/938BjapD7MAjwFr3M9/EOQsl5OIG3sGZJ8nFOTD9rjLjBGKA94GNOGfdtA5g3Btxxt4L/n1OCbW4S4q9yPatuJPUoRZ70YcttWGMMcaTDTEZY4zxZAnCGGOMJ0sQxhhjPFmCMMYY48kShDHGGE+WIIwJAHfZkHbBjsOYirDTXI0xxniyHoQxFSQidUXkYxFZIc79Ia4Xka9EJEVEhorIcvexTkS2uG26icjXIrJMROYWLH1hTCixBGFMxQ0CdqlqJ1W9CPi0YIOqzlLVzqraGWfd/2fcNb8mA9epajdgGjAxGIEbU5qIYAdgTA3wI86B/0mcpU4WSJEbw4nIfcAxVX1BRC4CLgL+7dYLx1mawZiQYgnCmApS1fUi0g1n7a7HReQz3+0i0h8YgXOnMXCWa16tqpdUbaTGlI8NMRlTQSJyDpCtqm/h3Eioq8+2JOBF4NeqeswtXgfEi8glbp1IEWlfxWEbUybrQRhTcR2Ap0UkH2cFz9/jJApw7lXdGJjpDiftUtWrROQ64DkRicP5dzgJWF3VgRtTGjvN1RhjjCcbYjLGGOPJEoQxxhhPliCMMcZ4sgRhjDHGkyUIY4wxnixBGGOM8WQJwhhjjKf/D1ToBwA/x+bBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), 'o-', color=\"g\", label=\"Train score\")\n",
    "plt.plot(train_sizes, test_scores.mean(axis=1), 'o-', color=\"r\", label=\"Test score\")\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"roc_auc\")\n",
    "plt.title('Learning curves')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Рост качества на тестовой выборке замедляется примерно с 12000 объектов, но тем не менее качество растет, модель строится быстро, поэтому оставим все объекты в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не отток:16922\n",
      "Oтток:1377\n"
     ]
    }
   ],
   "source": [
    "print('Не отток:{}'.format(sum(y==-1)))\n",
    "print('Oтток:{}'.format(sum(y==1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Балансировка 20/80 (не отток/отток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance 20/80:0.7172549711533766\n"
     ]
    }
   ],
   "source": [
    "w0=0.2\n",
    "w1=0.8\n",
    "weights = np.array([w0 if r==-1 else w1 for r in y_train])\n",
    "balance_20_80 = cross_val_score(GBclf, X_train, y_train, cv=cv_strategy, scoring='roc_auc', \n",
    "                                fit_params={'sample_weight': weights}, ).mean()\n",
    "print ('Balance 20/80:  {}'.format(balance_20_80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Балансировка 80/20 (не отток/отток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance 80/20: 0.7191785870640565\n"
     ]
    }
   ],
   "source": [
    "w0=0.8\n",
    "w1=0.2\n",
    "weights = np.array([w0 if r==-1 else w1 for r in y_train])\n",
    "balance_80_20 = cross_val_score(GBclf, X_train, y_train, cv=cv_strategy, scoring='roc_auc', \n",
    "                                fit_params={'sample_weight': weights}, ).mean()\n",
    "print ('Balance 80/20: {}'.format(balance_80_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Балансировка 50/50 (не отток/отток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance 50/50: 0.7189936650704152\n"
     ]
    }
   ],
   "source": [
    "w0=0.5\n",
    "w1=0.5\n",
    "weights = np.array([w0 if r==-1 else w1 for r in y_train])\n",
    "balance_50_50 = cross_val_score(GBclf, X_train, y_train, cv=cv_strategy, scoring='roc_auc', \n",
    "                                fit_params={'sample_weight': weights}, ).mean()\n",
    "print ('Balance 50/50: {}'.format(balance_50_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Балансировка 70/30 (не отток/отток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance 70/30: 0.718810360652965\n"
     ]
    }
   ],
   "source": [
    "w0=0.7\n",
    "w1=0.3\n",
    "weights = np.array([w0 if r==-1 else w1 for r in y_train])\n",
    "balance_70_30 = cross_val_score(GBclf, X_train, y_train, cv=cv_strategy, scoring='roc_auc', \n",
    "                                fit_params={'sample_weight': weights}, ).mean()\n",
    "print ('Balance 70/30: {}'.format(balance_70_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Балансировка 60/40 (не отток/отток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance 60/40: 0.7196468024665167\n"
     ]
    }
   ],
   "source": [
    "w0=0.6\n",
    "w1=0.4\n",
    "weights = np.array([w0 if r==-1 else w1 for r in y_train])\n",
    "balance_60_40 = cross_val_score(GBclf, X_train, y_train, cv=cv_strategy, scoring='roc_auc', \n",
    "                                fit_params={'sample_weight': weights}, ).mean()\n",
    "print ('Balance 60/40: {}'.format(balance_60_40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Балансировка 55/45 (не отток/отток)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance 55/45: 0.719775502296138\n"
     ]
    }
   ],
   "source": [
    "w0=0.55\n",
    "w1=0.45\n",
    "weights = np.array([w0 if r==-1 else w1 for r in y_train])\n",
    "balance_55_45 = cross_val_score(GBclf, X_train, y_train, cv=cv_strategy, scoring='roc_auc', \n",
    "                                fit_params={'sample_weight': weights}, ).mean()\n",
    "print ('Balance 55/45: {}'.format(balance_55_45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Лучший результат дала балансировка 55/45, но оценка все равно ниже, чем без балансировки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количеству отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "-1.0    964\n",
      " 1.0    964\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "count_no_outflow, count_outflow = y_train.value_counts()\n",
    "\n",
    "#Возьмем из группы \"не отток\" столько же элементов, сколько в оттоке\n",
    "df_no_outflow = data_train[data_train['labels'] == -1]\n",
    "df_outflow = data_train[data_train['labels'] == 1]\n",
    "df_no_outflow_under = df_no_outflow.sample(count_outflow)\n",
    "data_undersampling = shuffle(pd.concat([df_no_outflow_under, df_outflow], axis=0))\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(data_undersampling.labels.value_counts())\n",
    "\n",
    "X_train1 = data_undersampling.iloc[:,:-1]\n",
    "y_train1 = data_undersampling.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7026243720760308"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train1, y_train1, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First undersampling:\n",
      "-1.0    1184\n",
      " 1.0     964\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Уберем конец в классе \"не отток\", оставив 10% от выборки, чтобы примерно уравновесить кол-во объектов разных классов\n",
    "df_no_outflow = data_train[data_train['labels'] == -1].iloc[:int(count_no_outflow/10), :]\n",
    "df_outflow = data_train[data_train['labels'] == 1]\n",
    "data_undersampling = shuffle(pd.concat([df_no_outflow, df_outflow], axis=0))\n",
    "\n",
    "print('First undersampling:')\n",
    "print(data_undersampling.labels.value_counts())\n",
    "\n",
    "X_train2 = data_undersampling.iloc[:,:-1]\n",
    "y_train2 = data_undersampling.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967379807095515"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train2, y_train2, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last undersampling:\n",
      "-1.0    1184\n",
      " 1.0     964\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Уберем начало в классе \"не отток\", оставив 10% от выборки, чтобы примерно уравновесить кол-во объектов разных классов\n",
    "df_no_outflow = data_train[data_train['labels'] == -1].iloc[-int(count_no_outflow/10):, :]\n",
    "df_outflow = data_train[data_train['labels'] == 1]\n",
    "data_undersampling = shuffle(pd.concat([df_no_outflow, df_outflow], axis=0))\n",
    "\n",
    "print('Last undersampling:')\n",
    "print(data_undersampling.labels.value_counts())\n",
    "\n",
    "X_train3 = data_undersampling.iloc[:,:-1]\n",
    "y_train3 = data_undersampling.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7021708244958071"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train3, y_train3, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Во всех трех случаях качество значительно снизилось, поэтому не будем делать Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски у числовых переменных нулями. Для этого в третьей сверху ячейки с кодом заменим код на: X_num = X_num.fillna(0). Все остальные ячейки по обработке данных и построению модели оставляем без изменений, запускаем их, после проверяем качество на кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151944046353628"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем заполнить пропуски аномальными значениями: -999. Код соотвественно X_num = X_num.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71290703343088"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### В обоих случаях качество снизилось, поэтому оставляем изначальный вариант заполнения средними значениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем стратегию LabelEncoder(). Для этого нужно выполнить первые три ячейки с кодом, затем указанную ниже ячейку, пропустить ячейку с удалением категориальных признаков, у которых более 50 разных категорий, пропустить ячейку с Onehotencoder, остальные ячейки выполнить по порядку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X_cat.fillna('Na', axis=0).applymap(str)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for j in range(X_cat.shape[1]):\n",
    "    le.fit(X_cat.iloc[:,j])\n",
    "    X_cat.iloc[:,j] = le.transform(X_cat.iloc[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.721599828646281"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим каждую категорию числом входящих в неё объектов (запуск ячеек аналогично тому, как было в предыдущих пунктах)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X_cat.fillna('Na', axis=0).applymap(str)\n",
    "\n",
    "for j in range(X_cat.shape[1]):                            \n",
    "    X_cat.iloc[:,j] = X_cat.iloc[:,j].map(X_cat.groupby(X_cat.columns[j]).size())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7237989268953984"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Оставляем последний вариант (каждая ячейка заполнена числом входящих в нее объектов), т.к. при такой обработке модель показывает наилучшее качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль sklearn.feature_selection). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (sklearn.linear_model.Lasso). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше применена следующая стратегия: удаление признаков, у которых пропущено более 70% данных, и дополнительно удаление категориальных признаков, у которых более 50 различных категорий. Попробуем другие стратегии.\n",
    "\n",
    "* Проведем отбор на основе важности признаков через feature_importances_ построенной модели. Удалим признаки с нулевой важностью (среди уже отобранных признаков) и построим модель на новом наборе признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18299, 74)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBclf.fit(X,y)\n",
    "importance = GBclf.feature_importances_\n",
    "importance = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importance}) \n",
    "importance = importance.sort_values(by = importance.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_del=[]\n",
    "for i in range(importance.shape[0]):\n",
    "    if importance.Importance[i]==0: import_del.append(importance.Feature[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18299, 65)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_importance = X.drop(columns=import_del)\n",
    "X_importance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_importance, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7239034564914838"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели немного улучшилось. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Отбор наиболее связанных с целевой переменной признаков на основе статистического критерия. \n",
    "Применяем к обработанным ранее данным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectKBest(k=65)\n",
    "select.fit(X, y)\n",
    "X = select.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7268796668212248"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Отбираем 65 наиболее связанных с целевой переменной признаков (Пробовала разные варианты, но с числом признаков, равных 65, модель показала наилучший результат). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'presort', 'random_state', 'subsample', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBclf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Случайный поиск параметров по сетке\n",
    "parameters_grid = {'n_estimators' : np.arange(70, 200, 10),\n",
    "                  'learning_rate': np.arange(0.02, 0.12, 0.02),\n",
    "                   'max_depth': np.arange(3, 10),\n",
    "                   'max_features': np.arange(25, 75, 10),\n",
    "                   'subsample': np.arange(0.2, 1.2, 0.2),\n",
    "                  }\n",
    "grid_cv = RandomizedSearchCV(GBclf, parameters_grid, scoring = 'roc_auc', cv = cv_strategy, n_iter=30, n_jobs=-1)\n",
    "\n",
    "#'random_state': np.arange(0, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "0.7274880824590555\n",
      "{'subsample': 1.0, 'n_estimators': 110, 'max_features': 45, 'max_depth': 3, 'learning_rate': 0.08}\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "grid_cv.fit(X_train, y_train)  \n",
    "print(grid_cv.best_score_)\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подбор параметров на основе предыдущего отбора\n",
    "parameters = {'n_estimators' : np.arange(100, 130, 10),\n",
    "              'learning_rate': np.arange(0.07, 0.1, 0.01),\n",
    "              'max_depth': np.arange(2, 5),\n",
    "              'max_features': np.arange(35, 65, 10),\n",
    "              'subsample': [1]\n",
    "              }\n",
    "grid_cv = GridSearchCV(GBclf, parameters, scoring='roc_auc', n_jobs=-1, cv=cv_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731837197957033\n",
      "{'learning_rate': 0.08, 'max_depth': 2, 'max_features': 35, 'n_estimators': 120, 'subsample': 1}\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_cv.fit(X_train, y_train)\n",
    "print(grid_cv.best_score_)\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_estimators': 120,\n",
    "                'max_depth': 2,\n",
    "                'learning_rate': 0.08,\n",
    "                'max_features': 35,\n",
    "                'subsample': 1\n",
    "                }\n",
    "GBclf = GradientBoostingClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7298722909927525"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GBclf, X_train, y_train, scoring = 'roc_auc', cv=cv_strategy).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### За счет подбора параметров качество модели улучшилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод feature_importances_ - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Var113</td>\n",
       "      <td>0.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Var160</td>\n",
       "      <td>0.101077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Var217</td>\n",
       "      <td>0.079165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var94</td>\n",
       "      <td>0.077346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Var216</td>\n",
       "      <td>0.070274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Var119</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Var149</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Var144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Var229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "22  Var113    0.242900\n",
       "33  Var160    0.101077\n",
       "55  Var217    0.079165\n",
       "19   Var94    0.077346\n",
       "54  Var216    0.070274\n",
       "..     ...         ...\n",
       "23  Var119    0.000000\n",
       "1    Var13    0.000000\n",
       "31  Var149    0.000000\n",
       "30  Var144    0.000000\n",
       "64  Var229    0.000000\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = GBclf.feature_importances_\n",
    "importance = pd.DataFrame({\"Feature\": X_importance.columns, \"Importance\": importance}) \n",
    "importance = importance.sort_values(by = importance.columns[1], ascending=False)\n",
    "importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### В начале выведены признаки, внесшие наибольший вклад в модель, в конце - наименьший"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли между этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBclf = GradientBoostingClassifier(**model_params, random_state=1)\n",
    "GBclf.fit(X_train, y_train)\n",
    "predictions = GBclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = [i for i, k in enumerate(zip(predictions, y_test.values)) if k[0]!=k[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321.124375</td>\n",
       "      <td>6.821836</td>\n",
       "      <td>1253.625278</td>\n",
       "      <td>236.344888</td>\n",
       "      <td>292.660892</td>\n",
       "      <td>4.530059</td>\n",
       "      <td>97.28745</td>\n",
       "      <td>224.440225</td>\n",
       "      <td>0.730775</td>\n",
       "      <td>2.578824e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>209.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.807556e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3605.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1636.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.555200e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6285.0</td>\n",
       "      <td>4552.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>924.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>286.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.205574e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>6665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>334.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>4552.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1321.124375</td>\n",
       "      <td>6.821836</td>\n",
       "      <td>1253.625278</td>\n",
       "      <td>236.344888</td>\n",
       "      <td>292.660892</td>\n",
       "      <td>4.530059</td>\n",
       "      <td>97.28745</td>\n",
       "      <td>224.440225</td>\n",
       "      <td>0.730775</td>\n",
       "      <td>2.578824e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>280.00000</td>\n",
       "      <td>230.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.341006e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1512.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>176.00000</td>\n",
       "      <td>166.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.094486e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>959.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>253.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.806400e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14781.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>16021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>868.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2252.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>166.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.0</td>\n",
       "      <td>22917.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20929.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5935.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>19908.0</td>\n",
       "      <td>18485.0</td>\n",
       "      <td>6665.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1            2           3           4          5   \\\n",
       "0    1321.124375   6.821836  1253.625278  236.344888  292.660892   4.530059   \n",
       "1     140.000000   0.000000     0.000000  332.000000  415.000000   4.000000   \n",
       "2    3605.000000  28.000000  1636.000000  136.000000  170.000000   0.000000   \n",
       "3     924.000000   7.000000   440.000000  204.000000  255.000000   0.000000   \n",
       "4       0.000000   0.000000     0.000000    8.000000   10.000000   0.000000   \n",
       "..           ...        ...          ...         ...         ...        ...   \n",
       "408  1321.124375   6.821836  1253.625278  236.344888  292.660892   4.530059   \n",
       "409   252.000000   0.000000     0.000000  480.000000  600.000000   4.000000   \n",
       "410  1512.000000   7.000000    36.000000  288.000000  360.000000  10.000000   \n",
       "411   959.000000   7.000000   392.000000  128.000000  160.000000   0.000000   \n",
       "412   868.000000   7.000000  2252.000000   68.000000   85.000000   6.000000   \n",
       "\n",
       "            6           7         8             9   ...       55       56  \\\n",
       "0     97.28745  224.440225  0.730775  2.578824e+06  ...  14336.0  22917.0   \n",
       "1     32.00000  209.120000  0.000000  2.807556e+06  ...  13550.0   2898.0   \n",
       "2     24.00000  200.000000  0.000000  1.555200e+06  ...  13550.0  22917.0   \n",
       "3     80.00000  286.960000  0.000000  4.205574e+06  ...  14336.0  22917.0   \n",
       "4      0.00000  334.400000  0.000000  0.000000e+00  ...  13550.0  22917.0   \n",
       "..         ...         ...       ...           ...  ...      ...      ...   \n",
       "408   97.28745  224.440225  0.730775  2.578824e+06  ...  14336.0  22917.0   \n",
       "409  280.00000  230.560000  0.000000  4.341006e+06  ...  14336.0  22917.0   \n",
       "410  176.00000  166.560000  0.000000  2.094486e+06  ...  14336.0  22917.0   \n",
       "411    0.00000  253.520000  0.000000  9.806400e+06  ...  13550.0  22917.0   \n",
       "412   24.00000  166.560000  0.000000  0.000000e+00  ...  13550.0  22917.0   \n",
       "\n",
       "       57       58    59       60      61       62       63       64  \n",
       "0    46.0  20929.0  46.0  14781.0   737.0  19908.0  18485.0  16021.0  \n",
       "1    24.0  20929.0  24.0  14781.0  1218.0  19908.0  18485.0  16021.0  \n",
       "2    19.0  20929.0  19.0   6285.0  4552.0  19908.0    759.0   6665.0  \n",
       "3    27.0  20929.0  27.0  14781.0  2720.0  19908.0  18485.0   6665.0  \n",
       "4    27.0  20929.0  27.0  14781.0  4552.0  19908.0  18485.0  16021.0  \n",
       "..    ...      ...   ...      ...     ...      ...      ...      ...  \n",
       "408  27.0  20929.0  27.0  14781.0   832.0  19908.0  18485.0  16021.0  \n",
       "409  13.0  20929.0  13.0  14781.0   737.0  19908.0  18485.0  16021.0  \n",
       "410   1.0   1768.0   1.0  14781.0  2720.0   1331.0  18485.0  16021.0  \n",
       "411  17.0  20929.0  17.0  14781.0  1456.0  19908.0  18485.0  16021.0  \n",
       "412  25.0  20929.0  25.0   5935.0  1262.0  19908.0  18485.0   6665.0  \n",
       "\n",
       "[413 rows x 65 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test[bad,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    409\n",
       "-1.0      4\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[bad].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>4.130000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>413.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1056.378880</td>\n",
       "      <td>4.899724</td>\n",
       "      <td>739.444334</td>\n",
       "      <td>222.238295</td>\n",
       "      <td>274.721909</td>\n",
       "      <td>3.967902</td>\n",
       "      <td>85.755928</td>\n",
       "      <td>220.337063</td>\n",
       "      <td>0.904079</td>\n",
       "      <td>2.694469e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13057.927361</td>\n",
       "      <td>19368.595642</td>\n",
       "      <td>133.847458</td>\n",
       "      <td>17873.220339</td>\n",
       "      <td>133.847458</td>\n",
       "      <td>11877.002421</td>\n",
       "      <td>1945.769976</td>\n",
       "      <td>16434.261501</td>\n",
       "      <td>15133.895884</td>\n",
       "      <td>13080.530266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1400.938536</td>\n",
       "      <td>5.182667</td>\n",
       "      <td>1389.380341</td>\n",
       "      <td>365.872904</td>\n",
       "      <td>458.138247</td>\n",
       "      <td>7.965927</td>\n",
       "      <td>143.885408</td>\n",
       "      <td>74.404166</td>\n",
       "      <td>3.370172</td>\n",
       "      <td>2.897820e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3303.363296</td>\n",
       "      <td>7809.938694</td>\n",
       "      <td>459.130931</td>\n",
       "      <td>6908.466404</td>\n",
       "      <td>459.130931</td>\n",
       "      <td>4274.744694</td>\n",
       "      <td>1385.310132</td>\n",
       "      <td>7055.216443</td>\n",
       "      <td>6907.362623</td>\n",
       "      <td>4530.423679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1298.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5568.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>329.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>176.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.742200e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.000000</td>\n",
       "      <td>22917.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20929.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6285.000000</td>\n",
       "      <td>814.000000</td>\n",
       "      <td>19908.000000</td>\n",
       "      <td>18485.000000</td>\n",
       "      <td>6665.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>784.000000</td>\n",
       "      <td>6.821836</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>220.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.409168e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13550.000000</td>\n",
       "      <td>22917.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>20929.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>14781.000000</td>\n",
       "      <td>1456.000000</td>\n",
       "      <td>19908.000000</td>\n",
       "      <td>18485.000000</td>\n",
       "      <td>16021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1321.124375</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1253.625278</td>\n",
       "      <td>236.344888</td>\n",
       "      <td>292.660892</td>\n",
       "      <td>4.530059</td>\n",
       "      <td>97.287450</td>\n",
       "      <td>254.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.205574e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.000000</td>\n",
       "      <td>22917.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>20929.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14781.000000</td>\n",
       "      <td>2720.000000</td>\n",
       "      <td>19908.000000</td>\n",
       "      <td>18485.000000</td>\n",
       "      <td>16021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14798.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>10524.000000</td>\n",
       "      <td>4388.000000</td>\n",
       "      <td>5485.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>525.760000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.451520e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>14336.000000</td>\n",
       "      <td>22917.000000</td>\n",
       "      <td>2534.000000</td>\n",
       "      <td>20929.000000</td>\n",
       "      <td>2534.000000</td>\n",
       "      <td>14781.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>19908.000000</td>\n",
       "      <td>18485.000000</td>\n",
       "      <td>16021.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           1             2            3            4   \\\n",
       "count    413.000000  413.000000    413.000000   413.000000   413.000000   \n",
       "mean    1056.378880    4.899724    739.444334   222.238295   274.721909   \n",
       "std     1400.938536    5.182667   1389.380341   365.872904   458.138247   \n",
       "min        0.000000    0.000000      0.000000     0.000000     0.000000   \n",
       "25%      329.000000    0.000000      0.000000   116.000000   135.000000   \n",
       "50%      784.000000    6.821836     60.000000   148.000000   180.000000   \n",
       "75%     1321.124375    7.000000   1253.625278   236.344888   292.660892   \n",
       "max    14798.000000   28.000000  10524.000000  4388.000000  5485.000000   \n",
       "\n",
       "               5            6           7           8             9   ...  \\\n",
       "count  413.000000   413.000000  413.000000  413.000000  4.130000e+02  ...   \n",
       "mean     3.967902    85.755928  220.337063    0.904079  2.694469e+06  ...   \n",
       "std      7.965927   143.885408   74.404166    3.370172  2.897820e+06  ...   \n",
       "min      0.000000     0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
       "25%      0.000000     8.000000  176.560000    0.000000  3.742200e+04  ...   \n",
       "50%      2.000000    48.000000  220.080000    0.000000  2.409168e+06  ...   \n",
       "75%      4.530059    97.287450  254.640000    0.000000  4.205574e+06  ...   \n",
       "max    122.000000  1680.000000  525.760000   30.000000  1.451520e+07  ...   \n",
       "\n",
       "                 55            56           57            58           59  \\\n",
       "count    413.000000    413.000000   413.000000    413.000000   413.000000   \n",
       "mean   13057.927361  19368.595642   133.847458  17873.220339   133.847458   \n",
       "std     3303.363296   7809.938694   459.130931   6908.466404   459.130931   \n",
       "min      413.000000    153.000000     1.000000    152.000000     1.000000   \n",
       "25%    13550.000000  22917.000000    14.000000  20929.000000    14.000000   \n",
       "50%    13550.000000  22917.000000    26.000000  20929.000000    26.000000   \n",
       "75%    14336.000000  22917.000000    40.000000  20929.000000    40.000000   \n",
       "max    14336.000000  22917.000000  2534.000000  20929.000000  2534.000000   \n",
       "\n",
       "                 60           61            62            63            64  \n",
       "count    413.000000   413.000000    413.000000    413.000000    413.000000  \n",
       "mean   11877.002421  1945.769976  16434.261501  15133.895884  13080.530266  \n",
       "std     4274.744694  1385.310132   7055.216443   6907.362623   4530.423679  \n",
       "min     1298.000000   206.000000    336.000000      3.000000   5568.000000  \n",
       "25%     6285.000000   814.000000  19908.000000  18485.000000   6665.000000  \n",
       "50%    14781.000000  1456.000000  19908.000000  18485.000000  16021.000000  \n",
       "75%    14781.000000  2720.000000  19908.000000  18485.000000  16021.000000  \n",
       "max    14781.000000  4552.000000  19908.000000  18485.000000  16021.000000  \n",
       "\n",
       "[8 rows x 65 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test[bad,:]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сложно однозначно сказать, почему ошибка достигается именно на данных объектах, возможно они являются выбросами. Также мы видим, что модель намного чаще совершает ошибку на объектах класса \"отток\", то есть страдает полнота модели, модель пропускает клиентов, которые собираются от нас уйти. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Обработка данных: удаление признаков, у которых пропущено более 70% информации; заполнение пропусков у числовых признаков средним значением; кодировка категориальных признаков числом входящих в категорию объектов; отбор 65 наиболее важных признаков. Модель GradientBoostingClassifier. Параметры модели: model_params = {'n_estimators': 120, 'max_depth': 2, 'learning_rate': 0.08, 'max_features': 35, 'subsample': 1 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Можно попробовать другие варианты отбора признаков в сочетании с разными кодировками категориальных признаков и заполнением пропусков. Cледует попробовать удалить выбросы из обучающей выборки."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
